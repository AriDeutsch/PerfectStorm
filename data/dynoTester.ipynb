{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3256de35-d9eb-4a8e-b75b-c3086042f7f8",
   "metadata": {},
   "source": [
    "## Following section tests dynamic normalisation, rgb and grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc69ad0b-024c-4627-ade1-40a5df2f5dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import sys \n",
    "import os\n",
    "# import torch, torchvision\n",
    "import numpy as np\n",
    "import time\n",
    "sys.path.append(os.path.abspath(\"kx59/pytorch-CycleGAN-and-pix2pix/data\"))\n",
    "from image_folder import default_loader\n",
    "from image_folder import make_dataset, dynamic_normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a383636f-e207-4981-a777-157a438e88e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainA = '/home/arid/kx59/pytorch-CycleGAN-and-pix2pix/datasets/datasetSS1to4/trainA'\n",
    "trainB = '/home/arid/kx59/pytorch-CycleGAN-and-pix2pix/datasets/datasetSS1to4/trainB'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57141267-3207-4b06-bbe6-a073e792efeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAimgs = make_dataset(trainA)\n",
    "trainBimgs = make_dataset(trainB)\n",
    "imgs = trainAimgs+trainBimgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0308c367-8fa9-48e1-b44f-db3e34ea8c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: [0.33871121 0.43935299 0.46356142]\n",
      "Std: [0.18485617 0.1683456  0.16552058]\n",
      "Average per image time: 0.01151 seconds\n",
      "Total time for 36000 images: 414.53570 seconds\n"
     ]
    }
   ],
   "source": [
    "stats = dynamic_normalisation(trainAimgs,trainBimgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5d83cd9e-b28d-4773-9bb3-04e920a8a6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: [0.411987]\n",
      "Std: [0.16804034]\n",
      "Average per image time: 0.01186 seconds\n",
      "Total time for 36000 images: 426.93984 seconds\n"
     ]
    }
   ],
   "source": [
    "statsGray = dynamic_normalisation(trainAimgs,trainBimgs,grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1007b663-3b76-4312-b519-a1b074c7ab52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean': array([0.33871121, 0.43935299, 0.46356142]), 'std': array([0.18485617, 0.1683456 , 0.16552058])}\n",
      "{'mean': 0.41198699800872557, 'std': 0.16804033900366813}\n"
     ]
    }
   ],
   "source": [
    "print(stats)\n",
    "print(statsGray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "651c9251-bdae-4b97-852e-ad7a0c49fcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_image_stats(paths, gray=False):\n",
    "    images = []\n",
    "    start_time = time.time()\n",
    "    for path in paths:\n",
    "        with Image.open(path) as image:\n",
    "            if gray:\n",
    "                image = image.convert('L') # convert to grayscale\n",
    "            images.append(np.array(image)/255)\n",
    "                \n",
    "\n",
    "    mean = np.mean(images, axis=(0, 1, 2), dtype=np.float64) # calculate mean of all pixels. Will return individual stats for each channel\n",
    "    std = np.std(images, axis=(0, 1, 2), dtype=np.float64) # calculate standard deviation of all pixels. Will return individual stats for each channel\n",
    "    end_time = time.time()-start_time\n",
    "    print(f'Time taken: {end_time} seconds')\n",
    "    print(f'Time taken per image: {(end_time/len(paths))} seconds')\n",
    "    del images\n",
    "    return {'mean':mean, 'std':std}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f71a460-97b4-4ee0-ac65-d952120cfb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shifted_data_variance(paths, gray=False):\n",
    "    \"\"\"\n",
    "    Here we choose K to be an estimate of the mean per channel\n",
    "    We shift every pixel in a given channel by the associated K. \n",
    "    This ensures no cancellation will occur due to the subtraction \n",
    "    during the 'var' assignment statement, otherwise a potential \n",
    "    cancellation could ruin the natural precision. This does not \n",
    "    change the variance, and thus standard deviation, since Var(X) = Var(X-K)\n",
    "    \"\"\"\n",
    "    Sums = []\n",
    "    SSq = []\n",
    "    K = (0.412 if gray else np.array([0.338, 0.439, 0.463]).reshape(1,1,3))\n",
    "    totalPix = 0 # counter for total number of pixels in dataset\n",
    "    # if gray:\n",
    "    #     K = np.array(0.412)\n",
    "    # else:\n",
    "    #     K = np.array([0.338, 0.439, 0.463])\n",
    "    start_time = time.time()\n",
    "    for path in paths:\n",
    "        with Image.open(path) as image:\n",
    "            if gray:\n",
    "                image = image.convert('L') # convert to grayscale\n",
    "            else:\n",
    "                image = image.convert('RGB')\n",
    "            image = np.array(image)/255\n",
    "            totalPix += image.shape[0]*image.shape[1] # increment by the image height*width, i.e. number of pixels per channel\n",
    "            \n",
    "            shift = image-K \n",
    "            \n",
    "            Sums.append(np.sum(shift,axis=(0,1))) # sum along the height and width (indices 0 and 1) but not along the channels\n",
    "            SSq.append(np.sum(shift**2,axis=(0,1))) # sum along the height and width (indices 0 and 1) but not along the channels\n",
    "            \n",
    "    TotalSum = np.sum(Sums,axis=0) # sum the appended items along the axis of appending\n",
    "    TotalSSq = np.sum(SSq,axis=0)\n",
    "    \n",
    "    mean = K + TotalSum/totalPix\n",
    "    var = (TotalSSq-TotalSum**2/totalPix)/(totalPix-1) \n",
    "    # use (totalPix) instead of (totalPix-1) if want to compute the exact variance of the given data\n",
    "    # use (totalPix-1) if data are samples of a larger population\n",
    "    std = np.sqrt(var)\n",
    "    \n",
    "    end_time = time.time()-start_time\n",
    "    print('Total time taken: %.6f seconds'%end_time)\n",
    "    print('Time taken per image: %.6f seconds'% (end_time/len(paths)))\n",
    "    del Sums, SSq\n",
    "    return {'mean':mean.flatten().tolist(),'std':std.flatten().tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f967d17e-11da-4321-a853-c8762eced039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken: 10.225380 seconds\n",
      "Time taken per image: 0.005113 seconds\n",
      "Shifted algorithm stats for rgb:\n",
      "{'mean': [0.34207764539408975, 0.4426478469903794, 0.4667692729826009], 'std': [0.1835496355033989, 0.16713516225989203, 0.16453067846727407]}\n"
     ]
    }
   ],
   "source": [
    "stats = shifted_data_variance(trainAimgs[:1000]+trainBimgs[:1000], gray=False)\n",
    "print('Shifted algorithm stats for rgb:')\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a4d2f2c-1066-4562-b245-3e600cec9224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken: 4.415672 seconds\n",
      "Time taken per image: 0.002208 seconds\n",
      "Shifted algorithm stats for grayscale:\n",
      "{'mean': [0.4152969037615046], 'std': [0.16675659848918725]}\n"
     ]
    }
   ],
   "source": [
    "stats = shifted_data_variance(trainAimgs[:1000]+trainBimgs[:1000], gray=True)\n",
    "print('Shifted algorithm stats for grayscale:')\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7abcd0d-4af0-49ee-ac47-22537578828a",
   "metadata": {},
   "source": [
    "## Next section checks the dimensions of saved intermediate images from CycleGAN model.\n",
    "\n",
    "Note: All images are three channels, even if it was supposed to be grayscale, the single channel is copied to three channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e31c028-c1b8-4c35-ba78-ba7b6de305f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outImgPath = '/scratch/kx59/arid/scratch_checkpoints/BS16_2gpuGrayscale/web/images/epoch001_fake_B.png' #BS16_2gpuGrayscale #in1out3\n",
    "fake_B_img = Image.open(outImgPath, 'r')\n",
    "print(fake_B_img.format)\n",
    "display(fake_B_img)\n",
    "fake_B_img = np.array(fake_B_img)\n",
    "print(fake_B_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f56173-3cdc-4287-91ca-9cb6e05b90e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fake_B_img[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226269e1-30d8-4004-8fe6-11f4ac52611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_A_ImgPath = '/scratch/kx59/arid/scratch_checkpoints/BS16_2gpuGrayscale/web/images/epoch001_real_A.png'\n",
    "real_A_img = Image.open(real_A_ImgPath, 'r')\n",
    "print(real_A_img.format)\n",
    "display(real_A_img)\n",
    "real_A_img = np.array(real_A_img)\n",
    "print(real_A_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f3610d-7091-4696-aae9-f287f89f7ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(real_A_img[0,0,:])\n",
    "truth_img = np.zeros_like(real_A_img[:,:,0])\n",
    "\n",
    "test1 = (real_A_img[:,:,0]==real_A_img[:,:,1]).all() and (real_A_img[:,:,1]==real_A_img[:,:,2]).all()\n",
    "print('Greyscale? %r' % test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8ab844-e642-455a-b161-6472c86f5683",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2]])\n",
    "b = np.array([[1,2]])\n",
    "c = np.array([[1,2]])\n",
    "print(a.shape, '\\n', a)\n",
    "print(b.shape, '\\n', b)\n",
    "print(c.shape, '\\n', c)\n",
    "test2 = (a==c).all() and (b==c).all()\n",
    "\n",
    "print(test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb72382-756b-4845-803a-2220d179a3fb",
   "metadata": {},
   "source": [
    "## Below is experimenting with json file loading of norm stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b456b84-b3f9-4d4f-9b9b-3944b24a6822",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "# obj0, obj1, obj2 are created here...\n",
    "mean = (0.6, 0.6, 0.6)\n",
    "std = (0.5, 0.5, 0.5)\n",
    "\n",
    "# Saving the objects:\n",
    "with open('stats.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump([mean, std], f)\n",
    "    \n",
    "with open('stats.pkl', 'ab') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump([mean, std], f)\n",
    "\n",
    "del mean, std\n",
    "try:\n",
    "    print(mean)\n",
    "except NameError as e:\n",
    "    print(e)\n",
    "try:\n",
    "    print(std)\n",
    "except NameError:\n",
    "    print(f'Std not defined: {NameError}')\n",
    "\n",
    "# Getting back the objects:\n",
    "with open('stats.pkl', 'rb') as f:  # Python 3: open(..., 'rb')\n",
    "    mean, std = pickle.load(f)\n",
    "    \n",
    "print(f'mean = {mean}', f'std = {std}', sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dbbfa6-49af-4f0f-b9d4-39caa743329f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "# obj0, obj1, obj2 are created here...\n",
    "mean = (0.6, 0.6, 0.6)\n",
    "std = (0.5, 0.5, 0.5)\n",
    "\n",
    "# Saving the objects:\n",
    "with open('stats.json', 'w') as f:  # Python 3: open(..., 'wb')\n",
    "    json.dump([mean, std], f)\n",
    "    \n",
    "with open('stats.pkl', 'a') as f:  # Python 3: open(..., 'wb')\n",
    "    json.dump([mean, std], f)\n",
    "\n",
    "del mean, std\n",
    "try:\n",
    "    print(mean)\n",
    "except NameError as e:\n",
    "    print(e)\n",
    "try:\n",
    "    print(std)\n",
    "except NameError:\n",
    "    print(f'Std not defined: {NameError}')\n",
    "\n",
    "# Getting back the objects:\n",
    "with open('stats.json', 'r') as f:  # Python 3: open(..., 'rb')\n",
    "    mean, std = json.load(f)\n",
    "    \n",
    "print(f'mean = {mean}', f'std = {std}', sep = '\\n')\n",
    "\n",
    "norm = transforms.Normalize(mean,std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246cf8a8-ae86-4455-a51e-16b1bc80329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obj0, obj1, obj2 are created here...\n",
    "# mean = np.array([0.6,0.6,0.6])\n",
    "# std = np.array([0.5,0.5,0.5])\n",
    "mean = [0.6,0.6,0.6]\n",
    "std = [0.5,0.5,0.5]\n",
    "stats = {'Mean':mean, 'Std':std}\n",
    "\n",
    "# Saving the objects:\n",
    "with open('stats.json', 'w') as f:\n",
    "    json.dump(stats, f)\n",
    "\n",
    "del stats,mean, std\n",
    "try:\n",
    "    print(mean)\n",
    "except NameError as e:\n",
    "    print(e)\n",
    "try:\n",
    "    print(std)\n",
    "except NameError as e:\n",
    "    print(e)\n",
    "\n",
    "# Getting back the objects:\n",
    "with open('stats.json', 'r') as f:\n",
    "    stats = json.load(f)\n",
    "    \n",
    "print(stats)\n",
    "mean = stats['Mean']\n",
    "std = stats['Std']\n",
    "print(f'mean = {mean}', f'std = {std}', sep = '\\n')\n",
    "norm = transforms.Normalize(mean,std)\n",
    "print(norm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
