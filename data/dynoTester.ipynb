{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3256de35-d9eb-4a8e-b75b-c3086042f7f8",
   "metadata": {},
   "source": [
    "## Following section tests dynamic normalisation, rgb and grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc69ad0b-024c-4627-ade1-40a5df2f5dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import sys \n",
    "import os\n",
    "# import torch, torchvision\n",
    "import numpy as np\n",
    "import time\n",
    "sys.path.append(os.path.abspath(\"kx59/pytorch-CycleGAN-and-pix2pix/data\"))\n",
    "from image_folder import default_loader\n",
    "from image_folder import make_dataset, dynamic_normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a383636f-e207-4981-a777-157a438e88e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainA = '/home/arid/kx59/pytorch-CycleGAN-and-pix2pix/datasets/datasetSS1to4/trainA'\n",
    "trainB = '/home/arid/kx59/pytorch-CycleGAN-and-pix2pix/datasets/datasetSS1to4/trainB'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57141267-3207-4b06-bbe6-a073e792efeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAimgs = make_dataset(trainA)\n",
    "trainBimgs = make_dataset(trainB)\n",
    "imgs = trainAimgs+trainBimgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0308c367-8fa9-48e1-b44f-db3e34ea8c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating normalisation stats\n",
      "Total time for dyno calculation taken: 0.100009 seconds\n",
      "Time taken per image for dyno calculation: 0.005000 seconds\n"
     ]
    }
   ],
   "source": [
    "stats = dynamic_normalisation(trainAimgs[:10],trainBimgs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d83cd9e-b28d-4773-9bb3-04e920a8a6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating normalisation stats\n",
      "Total time for dyno calculation taken: 0.059114 seconds\n",
      "Time taken per image for dyno calculation: 0.002956 seconds\n"
     ]
    }
   ],
   "source": [
    "statsGray = dynamic_normalisation(trainAimgs[:10],trainBimgs[:10],grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1007b663-3b76-4312-b519-a1b074c7ab52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean': [0.35970781281260583, 0.4653655055772522, 0.49396675467059087], 'std': [0.17775270614878358, 0.16966115086553138, 0.16806500877316496]}\n",
      "{'mean': [0.4370183112307423], 'std': [0.16660754845647935]}\n"
     ]
    }
   ],
   "source": [
    "print(stats)\n",
    "print(statsGray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8fedc2e-dbc2-47e7-84a6-953037a12c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, (3, 3)]\n"
     ]
    }
   ],
   "source": [
    "a = [1,2]\n",
    "a.append((3,3))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbe5ebe7-4bd3-477a-a0b2-a1bb8299ac10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.111111111111112"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "92*200/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "651c9251-bdae-4b97-852e-ad7a0c49fcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_image_stats(paths, gray=False):\n",
    "    images = []\n",
    "    start_time = time.time()\n",
    "    for path in paths:\n",
    "        with Image.open(path) as image:\n",
    "            if gray:\n",
    "                image = image.convert('L') # convert to grayscale\n",
    "            images.append(np.array(image)/255)\n",
    "                \n",
    "\n",
    "    mean = np.mean(images, axis=(0, 1, 2), dtype=np.float64) # calculate mean of all pixels. Will return individual stats for each channel\n",
    "    std = np.std(images, axis=(0, 1, 2), dtype=np.float64) # calculate standard deviation of all pixels. Will return individual stats for each channel\n",
    "    end_time = time.time()-start_time\n",
    "    print(f'Time taken: {end_time} seconds')\n",
    "    print(f'Time taken per image: {(end_time/len(paths))} seconds')\n",
    "    del images\n",
    "    return {'mean':mean, 'std':std}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f71a460-97b4-4ee0-ac65-d952120cfb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shifted_data_variance(paths, gray=False):\n",
    "    \"\"\"\n",
    "    Here we choose K to be an estimate of the mean per channel\n",
    "    We shift every pixel in a given channel by the associated K. \n",
    "    This ensures no cancellation will occur due to the subtraction \n",
    "    during the 'var' assignment statement, otherwise a potential \n",
    "    cancellation could ruin the natural precision. This does not \n",
    "    change the variance, and thus standard deviation, since Var(X) = Var(X-K)\n",
    "    \"\"\"\n",
    "    Sums = []\n",
    "    SSq = []\n",
    "    K = (0.412 if gray else np.array([0.338, 0.439, 0.463]).reshape(1,1,3))\n",
    "    totalPix = 0 # counter for total number of pixels in dataset\n",
    "    # if gray:\n",
    "    #     K = np.array(0.412)\n",
    "    # else:\n",
    "    #     K = np.array([0.338, 0.439, 0.463])\n",
    "    start_time = time.time()\n",
    "    for path in paths:\n",
    "        with Image.open(path) as image:\n",
    "            if gray:\n",
    "                image = image.convert('L') # convert to grayscale\n",
    "            else:\n",
    "                image = image.convert('RGB')\n",
    "            image = np.array(image)/255\n",
    "            totalPix += image.shape[0]*image.shape[1] # increment by the image height*width, i.e. number of pixels per channel\n",
    "            \n",
    "            shift = image-K \n",
    "            \n",
    "            Sums.append(np.sum(shift,axis=(0,1))) # sum along the height and width (indices 0 and 1) but not along the channels\n",
    "            SSq.append(np.sum(shift**2,axis=(0,1))) # sum along the height and width (indices 0 and 1) but not along the channels\n",
    "            \n",
    "    TotalSum = np.sum(Sums,axis=0) # sum the appended items along the axis of appending\n",
    "    TotalSSq = np.sum(SSq,axis=0)\n",
    "    \n",
    "    mean = (K + TotalSum/totalPix).flatten().tolist()\n",
    "    var = (TotalSSq-TotalSum**2/totalPix)/(totalPix-1) \n",
    "    # use (totalPix) instead of (totalPix-1) if want to compute the exact variance of the given data\n",
    "    # use (totalPix-1) if data are samples of a larger population\n",
    "    std = np.sqrt(var).flatten().tolist()\n",
    "    \n",
    "    end_time = time.time()-start_time\n",
    "    print('Total time for dyno calculation taken: %.6f seconds' % end_time)\n",
    "    print('Time taken per image for dyno calculation: %.6f seconds' % (end_time/len(paths)))\n",
    "    del Sums, SSq\n",
    "    if gray:\n",
    "        mean.append(mean[0])\n",
    "        mean.append(mean[0])\n",
    "        std.append(std[0])\n",
    "        std.append(std[0])\n",
    "    return {'mean':mean,'std':std}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f967d17e-11da-4321-a853-c8762eced039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for dyno calculation taken: 0.106050 seconds\n",
      "Time taken per image for dyno calculation: 0.005302 seconds\n",
      "Shifted algorithm stats for rgb:\n",
      "{'mean': [0.35970781281260583, 0.4653655055772522, 0.49396675467059087], 'std': [0.17775270614878358, 0.16966115086553138, 0.16806500877316496]}\n"
     ]
    }
   ],
   "source": [
    "stats = shifted_data_variance(trainAimgs[:10]+trainBimgs[:10], gray=False)\n",
    "print('Shifted algorithm stats for rgb:')\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a4d2f2c-1066-4562-b245-3e600cec9224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for dyno calculation taken: 0.042314 seconds\n",
      "Time taken per image for dyno calculation: 0.002116 seconds\n",
      "Shifted algorithm stats for grayscale:\n",
      "{'mean': [0.4370183112307423, 0.4370183112307423, 0.4370183112307423], 'std': [0.16660754845647935, 0.16660754845647935, 0.16660754845647935]}\n"
     ]
    }
   ],
   "source": [
    "stats = shifted_data_variance(trainAimgs[:10]+trainBimgs[:10], gray=True)\n",
    "print('Shifted algorithm stats for grayscale:')\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1537e04-ac21-48f0-890d-37cb1ba3bd42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1800/6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7abcd0d-4af0-49ee-ac47-22537578828a",
   "metadata": {},
   "source": [
    "## Next section checks the dimensions of saved intermediate images from CycleGAN model.\n",
    "\n",
    "Note: All images are three channels, even if it was supposed to be grayscale, the single channel is copied to three channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e31c028-c1b8-4c35-ba78-ba7b6de305f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outImgPath = '/scratch/kx59/arid/scratch_checkpoints/BS16_2gpuGrayscale/web/images/epoch001_fake_B.png' #BS16_2gpuGrayscale #in1out3\n",
    "fake_B_img = Image.open(outImgPath, 'r')\n",
    "print(fake_B_img.format)\n",
    "display(fake_B_img)\n",
    "fake_B_img = np.array(fake_B_img)\n",
    "print(fake_B_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f56173-3cdc-4287-91ca-9cb6e05b90e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fake_B_img[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226269e1-30d8-4004-8fe6-11f4ac52611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_A_ImgPath = '/scratch/kx59/arid/scratch_checkpoints/BS16_2gpuGrayscale/web/images/epoch001_real_A.png'\n",
    "real_A_img = Image.open(real_A_ImgPath, 'r')\n",
    "print(real_A_img.format)\n",
    "display(real_A_img)\n",
    "real_A_img = np.array(real_A_img)\n",
    "print(real_A_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f3610d-7091-4696-aae9-f287f89f7ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(real_A_img[0,0,:])\n",
    "truth_img = np.zeros_like(real_A_img[:,:,0])\n",
    "\n",
    "test1 = (real_A_img[:,:,0]==real_A_img[:,:,1]).all() and (real_A_img[:,:,1]==real_A_img[:,:,2]).all()\n",
    "print('Greyscale? %r' % test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8ab844-e642-455a-b161-6472c86f5683",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2]])\n",
    "b = np.array([[1,2]])\n",
    "c = np.array([[1,2]])\n",
    "print(a.shape, '\\n', a)\n",
    "print(b.shape, '\\n', b)\n",
    "print(c.shape, '\\n', c)\n",
    "test2 = (a==c).all() and (b==c).all()\n",
    "\n",
    "print(test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb72382-756b-4845-803a-2220d179a3fb",
   "metadata": {},
   "source": [
    "## Below is experimenting with json file loading of norm stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b456b84-b3f9-4d4f-9b9b-3944b24a6822",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "# obj0, obj1, obj2 are created here...\n",
    "mean = (0.6, 0.6, 0.6)\n",
    "std = (0.5, 0.5, 0.5)\n",
    "\n",
    "# Saving the objects:\n",
    "with open('stats.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump([mean, std], f)\n",
    "    \n",
    "with open('stats.pkl', 'ab') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump([mean, std], f)\n",
    "\n",
    "del mean, std\n",
    "try:\n",
    "    print(mean)\n",
    "except NameError as e:\n",
    "    print(e)\n",
    "try:\n",
    "    print(std)\n",
    "except NameError:\n",
    "    print(f'Std not defined: {NameError}')\n",
    "\n",
    "# Getting back the objects:\n",
    "with open('stats.pkl', 'rb') as f:  # Python 3: open(..., 'rb')\n",
    "    mean, std = pickle.load(f)\n",
    "    \n",
    "print(f'mean = {mean}', f'std = {std}', sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dbbfa6-49af-4f0f-b9d4-39caa743329f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "# obj0, obj1, obj2 are created here...\n",
    "mean = (0.6, 0.6, 0.6)\n",
    "std = (0.5, 0.5, 0.5)\n",
    "\n",
    "# Saving the objects:\n",
    "with open('stats.json', 'w') as f:  # Python 3: open(..., 'wb')\n",
    "    json.dump([mean, std], f)\n",
    "    \n",
    "with open('stats.pkl', 'a') as f:  # Python 3: open(..., 'wb')\n",
    "    json.dump([mean, std], f)\n",
    "\n",
    "del mean, std\n",
    "try:\n",
    "    print(mean)\n",
    "except NameError as e:\n",
    "    print(e)\n",
    "try:\n",
    "    print(std)\n",
    "except NameError:\n",
    "    print(f'Std not defined: {NameError}')\n",
    "\n",
    "# Getting back the objects:\n",
    "with open('stats.json', 'r') as f:  # Python 3: open(..., 'rb')\n",
    "    mean, std = json.load(f)\n",
    "    \n",
    "print(f'mean = {mean}', f'std = {std}', sep = '\\n')\n",
    "\n",
    "norm = transforms.Normalize(mean,std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "246cf8a8-ae86-4455-a51e-16b1bc80329c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'mean' is not defined\n",
      "name 'std' is not defined\n",
      "{'Mean': [0.6, 0.6, 0.6], 'Std': [0.5, 0.5, 0.5]}\n",
      "mean = [0.6, 0.6, 0.6]\n",
      "std = [0.5, 0.5, 0.5]\n",
      "Normalize(mean=[0.6, 0.6, 0.6], std=[0.5, 0.5, 0.5])\n"
     ]
    }
   ],
   "source": [
    "# obj0, obj1, obj2 are created here...\n",
    "# mean = np.array([0.6,0.6,0.6])\n",
    "# std = np.array([0.5,0.5,0.5])\n",
    "# import json\n",
    "# import torchvision.transforms as transforms\n",
    "mean = [0.6,0.6,0.6]\n",
    "std = [0.5,0.5,0.5]\n",
    "stats = {'Mean':mean, 'Std':std}\n",
    "\n",
    "# Saving the objects:\n",
    "with open('stats.json', 'w') as f:\n",
    "    json.dump(stats, f)\n",
    "\n",
    "del stats,mean, std\n",
    "try:\n",
    "    print(mean)\n",
    "except NameError as e:\n",
    "    print(e)\n",
    "try:\n",
    "    print(std)\n",
    "except NameError as e:\n",
    "    print(e)\n",
    "\n",
    "# Getting back the objects:\n",
    "with open('stats.json', 'r') as f:\n",
    "    stats = json.load(f)\n",
    "    \n",
    "print(stats)\n",
    "mean = stats['Mean']\n",
    "std = stats['Std']\n",
    "print(f'mean = {mean}', f'std = {std}', sep = '\\n')\n",
    "norm = transforms.Normalize(mean,std)\n",
    "print(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abad426b-3dfd-4695-b597-06640308f9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "a = 1\n",
    "b = 0\n",
    "res = True if not a and b else False\n",
    "print(res)\n",
    "\n",
    "a = 1\n",
    "b = 1\n",
    "res = True if not a and b else False\n",
    "print(res)\n",
    "\n",
    "a = 0\n",
    "btransforms\n",
    "res = True if not a and b else False\n",
    "print(res)\n",
    "\n",
    "a = 0\n",
    "b = 1\n",
    "res = True if not a and b else False\n",
    "print(res)\n",
    "\n",
    "a = 1\n",
    "b = 0\n",
    "res = True if (not a) and b else False\n",
    "print(res)\n",
    "\n",
    "a = 1\n",
    "b = 1\n",
    "res = True if (not a) and b else False\n",
    "print(res)\n",
    "\n",
    "a = 0\n",
    "b = 0\n",
    "res = True if (not a) and b else False\n",
    "print(res)\n",
    "\n",
    "a = 0\n",
    "b = 1\n",
    "res = True if (not a) and b else False\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf12c789-40a6-4380-81b6-51d9f1bbc019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b': 2}\n",
      "{'a': 1, 'b': 2}\n",
      "{'a': 1, 'b': 2, 'c': 3}\n",
      "{'a': 1, 'b': 2, 'c': 3}\n",
      "{'a': 1, 'b': 2, 'c': 3, 'd': 4}\n",
      "{'a': 1, 'b': 2, 'c': 3, 'd': 4}\n"
     ]
    }
   ],
   "source": [
    "b = {'a':1,'b':2}\n",
    "a = b\n",
    "print(a)\n",
    "print(b)\n",
    "a['c']=3\n",
    "print(a)\n",
    "print(b)\n",
    "b['d']=4\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45334ca4-7e92-4b9c-b9f5-9cdbfc55bffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/fs04/kx59/pytorch-CycleGAN-and-pix2pix/data/test.json\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(file)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241m.\u001b[39mdump(a,f)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# cwd = os.getcwd()\n",
    "# file = os.path.join(cwd,'test.json')\n",
    "# print(file)\n",
    "# with open(file,'w') as f:\n",
    "#     json.dump(a,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61aa9b7-88e8-48e8-bc6c-bc5215e1523c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
